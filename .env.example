# Database
CODEX_LB_DATABASE_URL=sqlite+aiosqlite:///~/.codex-lb/store.db
CODEX_LB_ACCOUNTS_DATABASE_URL=sqlite+aiosqlite:///~/.codex-lb/accounts.db
# Example (iCloud Drive):
# CODEX_LB_ACCOUNTS_DATABASE_URL=sqlite+aiosqlite:///~/Library/Mobile Documents/com~apple~CloudDocs/codex-lb/accounts.db

# Upstream ChatGPT base URL (no /codex suffix)
CODEX_LB_UPSTREAM_BASE_URL=https://chatgpt.com/backend-api

# Timeouts (seconds)
CODEX_LB_UPSTREAM_CONNECT_TIMEOUT_SECONDS=30
CODEX_LB_STREAM_IDLE_TIMEOUT_SECONDS=300

# OAuth / token refresh
CODEX_LB_AUTH_BASE_URL=https://auth.openai.com
CODEX_LB_OAUTH_CLIENT_ID=app_EMoamEEZ73f0CkXaXp7hrann
CODEX_LB_OAUTH_SCOPE="openid profile email"
CODEX_LB_OAUTH_TIMEOUT_SECONDS=30
CODEX_LB_OAUTH_REDIRECT_URI=http://localhost:1455/auth/callback
CODEX_LB_OAUTH_CALLBACK_HOST=127.0.0.1
# Do not change the port. OpenAI dislikes changes.
CODEX_LB_OAUTH_CALLBACK_PORT=1455
CODEX_LB_TOKEN_REFRESH_TIMEOUT_SECONDS=30
CODEX_LB_TOKEN_REFRESH_INTERVAL_DAYS=8

# Encryption key file (optional override; keep this with your accounts DB if you want accounts to roam)
# CODEX_LB_ENCRYPTION_KEY_FILE=/var/lib/codex-lb/encryption.key

# Upstream usage fetch
CODEX_LB_USAGE_FETCH_TIMEOUT_SECONDS=10
CODEX_LB_USAGE_FETCH_MAX_RETRIES=2
CODEX_LB_USAGE_REFRESH_ENABLED=true
CODEX_LB_USAGE_REFRESH_INTERVAL_SECONDS=60
CODEX_LB_USAGE_REFRESH_FETCH_CONCURRENCY=20

# Startup logging (debug)
# Logs the resolved Settings snapshot and an env allowlist (CODEX_LB_* + proxy env vars).
# Sensitive values (e.g. DATABASE_URL credentials, proxy userinfo) are redacted.
# Disabled by default to avoid log noise and reduce the risk of accidental secret exposure.
# CODEX_LB_STARTUP_LOG_CONFIG=true
# CODEX_LB_STARTUP_LOG_ENV=true

# Proxy request logging (debug).
# Disabled by default to reduce log I/O and avoid accidental metadata exposure in shared log sinks.
# CODEX_LB_LOG_PROXY_REQUEST_SHAPE=true
# CODEX_LB_LOG_PROXY_REQUEST_SHAPE_RAW_CACHE_KEY=true
# CODEX_LB_LOG_PROXY_REQUEST_PAYLOAD=true

# Persist stickiness key fingerprint to SQLite request logs (debug).
# When enabled, codex-lb stores a short HMAC fingerprint of `prompt_cache_key` in `request_logs.prompt_cache_key_hash`
# for postmortem correlation.
# Disabled by default to avoid extra DB growth and correlation metadata unless explicitly enabled.
# CODEX_LB_REQUEST_LOGS_PROMPT_CACHE_KEY_HASH_ENABLED=true

# Proxy account selection:
# Waste-pressure is always enabled. Legacy selection strategy configuration was removed.

# Proxy routing snapshot TTL (seconds).
# Higher values reduce DB reads under concurrency but can delay reacting to DB-driven changes
# (usage refresh results, dashboard toggles) by up to ~TTL seconds.
# Default (if unset): 10.0
# Typical tuned values:
# - 5â€“10: better throughput/latency under concurrency (common single-process tuning).
# - 1: more "fresh" routing based on DB changes.
# CODEX_LB_PROXY_SNAPSHOT_TTL_SECONDS=10

# Sticky sessions backend:
# - memory (default): fastest; per-process; resets on restart.
# - db: shared across processes; survives restart; adds DB write load on the proxy hot path.
# CODEX_LB_STICKY_SESSIONS_BACKEND=memory
